{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33226a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.compose import ColumnTransformer  \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif  \n",
    "from sklearn.metrics import (  \n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  \n",
    "from sklearn.svm import SVC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f25e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 1\n",
    "def load_and_clean_data():\n",
    "   \n",
    "    train_df = pd.read_csv(\"../files/input/train_data.csv.zip\",\n",
    "    index_col=False,\n",
    "    compression=\"zip\",)\n",
    "    test_df = pd.read_csv(\"../files/input/test_data.csv.zip\",\n",
    "    index_col=False,\n",
    "    compression=\"zip\",)\n",
    "\n",
    "    train_df = train_df.rename(columns={\"default payment next month\": \"default\"})\n",
    "    test_df = test_df.rename(columns={\"default payment next month\": \"default\"})\n",
    "\n",
    "    train_df = train_df.drop(columns=[\"ID\"])\n",
    "    test_df = test_df.drop(columns=[\"ID\"])\n",
    "   \n",
    "    train_df = train_df[train_df[\"EDUCATION\"] != 0]\n",
    "    train_df = train_df[train_df[\"MARRIAGE\"] != 0]\n",
    "    test_df = test_df[test_df[\"EDUCATION\"] != 0]\n",
    "    test_df = test_df[test_df[\"MARRIAGE\"] != 0]\n",
    "\n",
    "    train_df.loc[train_df[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n",
    "    test_df.loc[test_df[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed65c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 2\n",
    "def split_data(train_df, test_df):\n",
    "    \n",
    "    x_train = train_df.drop(columns=[\"default\"])\n",
    "    y_train = train_df[\"default\"]\n",
    "    x_test = test_df.drop(columns=[\"default\"])\n",
    "    y_test = test_df[\"default\"]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab5a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 3\n",
    "def create_pipeline(x_train: pd.DataFrame) -> Pipeline:\n",
    "\n",
    "    categorical_cols = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "    numerical_cols = [col for col in x_train.columns if col not in categorical_cols]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\",OneHotEncoder(),categorical_cols),\n",
    "            (\"num\", StandardScaler(), numerical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"pre\", preprocessor),\n",
    "        (\"sel\", SelectKBest(score_func=f_classif, k=20)),\n",
    "        (\"pca\", PCA(n_components=None)),\n",
    "        (\"clf\", MLPClassifier(\n",
    "            hidden_layer_sizes=(50, 30, 40, 60),\n",
    "            alpha=0.26,\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=15000,\n",
    "            random_state=21\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322226f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_hyperparameters(pipeline, x_train, y_train):\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid={}, cv=10, scoring=\"balanced_accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d84a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5\n",
    "def save_model(model):\n",
    "\n",
    "    os.makedirs(\"../files/models\", exist_ok=True)\n",
    "\n",
    "    with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1d700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 6-7\n",
    "def calculate_and_save_metrics(model, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    os.makedirs(\"../files/output\", exist_ok=True)\n",
    "\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    train_metrics = {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"train\",\n",
    "        \"precision\": precision_score(y_train, y_train_pred, zero_division=0),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_train, y_train_pred),\n",
    "        \"recall\": recall_score(y_train, y_train_pred, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_train, y_train_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    test_metrics = {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"test\",\n",
    "        \"precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_test, y_test_pred),\n",
    "        \"recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_test_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    train_cm = {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": \"train\",\n",
    "        \"true_0\": {\"predicted_0\": int(cm_train[0, 0]), \"predicted_1\": int(cm_train[0, 1])},\n",
    "        \"true_1\": {\"predicted_0\": int(cm_train[1, 0]), \"predicted_1\": int(cm_train[1, 1])},\n",
    "    }\n",
    "\n",
    "    test_cm = {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": \"test\",\n",
    "        \"true_0\": {\"predicted_0\": int(cm_test[0, 0]), \"predicted_1\": int(cm_test[0, 1])},\n",
    "        \"true_1\": {\"predicted_0\": int(cm_test[1, 0]), \"predicted_1\": int(cm_test[1, 1])},\n",
    "    }\n",
    "\n",
    "    with open(\"../files/output/metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(train_metrics) + \"\\n\")\n",
    "        f.write(json.dumps(test_metrics) + \"\\n\")\n",
    "        f.write(json.dumps(train_cm) + \"\\n\")\n",
    "        f.write(json.dumps(test_cm) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c13efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = load_and_clean_data()\n",
    "x_train, y_train, x_test, y_test = split_data(train_df, test_df)\n",
    "pipeline = create_pipeline(x_train)\n",
    "model = optimize_hyperparameters(pipeline, x_train, y_train)\n",
    "save_model(model)\n",
    "calculate_and_save_metrics(model, x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
